
### 1.进程、线程和协程
- 进程：程序执行时的一个实例，一个进程至少包含一个线程，同进程里多个线程可共享数据，不同进程之间切换代价大
- 线程：cpu调度的基本单位，线程上下文切换代价比进程小，是进程的一个实体
- 协程：是一种用户态的轻量级线程，一个线程可包含多个协程。进程和线程都是同步，协程是异步

### 2.并行与并发
- 并行指多个事件在同一个时刻发生；并发指在某时刻只有一个事件在发生，某个时间段内由于 CPU 交替执行，可以发生多个事件。
- 并行没有对 CPU 资源的抢占；并发执行的线程需要对 CPU 资源进行抢占。
- 并行执行的线程之间不存在切换；并发操作系统会根据任务调度系统给线程分配线程的 CPU 执行时间，线程的执行会进行切换。

### 3.qps和tps区别
QPS：Queries Per Second，意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器（比如是读写分离的架构，就是读的服务器）在规定时间内所处理流量多少的衡量标准。  

TPS：TransactionsPerSecond，意思是每秒事务数，一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。  

tps，即每秒处理事务数，每个事务包括了如下3个过程：  
a.用户请求服务器  
b.服务器自己的内部处理（包含应用服务器、数据库服务器等）  
c.服务器返回给用户  
如果每秒能够完成N个这三个过程，tps就是N；

qps，如果是对一个页面请求一次，形成一个tps，但一次页面请求，可能产生多次对服务器的请求（页面上有很多html资源，比如图片等），服务器对这些请求，就可计入“Qps”之中；

 但是，如今的项目基本上都是前后端分离的，性能也分为前端性能和后端性能，通常默认是后端性能，即服务端性能，也就是对服务端接口做压测

如果是对一个接口（单场景）压测，且这个接口内部不会再去请求其它接口，那么tps=qps，否则，tps≠qps

如果是对多个接口（混合场景）压测，不加事务控制器，jmeter会统计每个接口的tps，而混合场景是要测试这个场景的tps，显然这样得不到混合场景的tps，所以，要加了事物控制器，结果才是整个场景的tps。

QPS（TPS）= 并发数/平均响应时间 或者 并发数 = QPS*平均响应时间
- 系统压力小的时候，并发数和QPS呈正相关，比如此时响应时间都小于1秒
- 当系统压力大的时候，比如响应时间远大于1秒，QPS可能会趋向最大值或反而会下降


### 4.多线程什么情况下使用
- 多数据并行处理
- 异步请求网络  （例如发短信发邮件通知等等，不影响主业务逻辑）
- IO密集型业务  （文件读写，数据库操作）

### 5.线程的生命周期
线程的生命周期包含5个阶段，包括：新建、就绪、运行、阻塞、销毁。
![img](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a3f55f43-64c7-42c2-8fd4-1389f90a6f66/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210122%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210122T162412Z&X-Amz-Expires=86400&X-Amz-Signature=ba540ec4c2bc5535c1788ad40f35faf8cf1695d4cb0c5e8bbb71c7333eea5527&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)
- 新建：就是刚使用new方法，new出来的线程；
- 就绪：就是调用的线程的start()方法后，这时候线程处于等待CPU分配资源阶段，谁先抢的CPU资源，谁开始执行;
- 运行：当就绪的线程被调度并获得CPU资源时，便进入运行状态，run方法定义了线程的操作和功能;
- 阻塞：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()、wait()之后线程就处于了阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify或者notifyAll()方法。唤醒的线程不会立刻执行run方法，它们要再次等待CPU分配资源进入运行状态;
- 销毁：如果线程正常执行完毕后或线程被提前强制性的终止或出现异常导致结束，那么线程就要被销毁，释放资源;

### 6.创建线程
- 继承 Thread 类，重写 run() 方法
- 实现 Runnable 接口，重写 run() 方法
- 实现 Callable 接口，使用 FutureTask 类创建线程

### 7.线程关键字相关
#### wait notify 机制
- 调用obj的wait(), notify()方法前，必须获得obj锁，即必须在同步代码块中使用（synchronized）；
- 调用obj.wait()后，线程A就释放了obj的；
- 当obj.wait()方法返回后，线程需要再次获得obj锁，才能继续执行；
- obj.notify()只能唤醒一个进行obj.wait()后的线程（具体哪一个由JVM决定）；
- obj.notifyAll()则能全部唤醒，但是要继续执行obj.wait()的下一条语句，必须获得obj锁，这由优先级和系统调度决定。

#### sleep 和 wait 区别
- sleep() 是 Thread 类的静态本地方法；wait() 是Object类的成员本地方法；
- sleep() 方法可以在任何地方使用；wait() 方法则只能在同步方法或同步代码块中使用，否则抛出异常`Exception in thread "Thread-0" java.lang.IllegalMonitorStateException`
- sleep() 会休眠当前线程指定时间，释放 CPU 资源，不释放对象锁，休眠时间到自动苏醒继续执行；wait() 方法放弃持有的对象锁，进入等待队列，当该对象被调用 notify() / notifyAll() 方法后才有机会竞争获取对象锁，进入运行状态
- JDK1.8 sleep() wait() 均需要捕获 `InterruptedException` 异常

####  volatile 和 synchronized 区别
- synchronized 表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其他线程；
- volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重排序。

#### synchronized 和 Lock
- 实现层面不一样。synchronized 是 Java 关键字，JVM层面 实现加锁和释放锁；Lock 是一个接口，在代码层面实现加锁和释放锁；
- 是否自动释放锁。synchronized 在线程代码执行完或出现异常时自动释放锁；Lock 不会自动释放锁，需要再 finally {} 代码块显式地中释放锁；
- 是否一直等待。synchronized 会导致线程拿不到锁一直等待；Lock 可以设置尝试获取锁或者获取锁失败一定时间超时；
- 获取锁成功是否可知。synchronized 无法得知是否获取锁成功；Lock 可以通过 tryLock 获得加锁是否成功；
- 功能复杂性。synchronized 加锁可重入、不可中断、非公平；Lock 可重入、可判断、可公平和不公平、细分读写锁提高效率。

#### yield
- 暂停当前正在执行的线程对象，不会释放资源锁！
- 和 sleep 不同的是 yield方法并不会让线程进入阻塞状态，而是让线程重回就绪状态，它只需要等待重新获取CPU执行时间，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。还有一点和 sleep 不同的是 yield 方法只能使同优先级或更高优先级的线程有执行的机会

#### join
等待该线程终止。
等待调用join方法的线程结束，再继续执行。如：t.join();//主要用于等待t线程运行结束，若无此句，main则会执行完毕，导致结果不可预测。

### 8.Lock 接口六个方法
- void lock() // 获取锁
- void lockInterruptibly() // 如果当前线程未被中断，则获取锁，可以响应中断(调用interrupt()方法)
- Condition newCondition() // 返回绑定到此 Lock 实例的新 Condition 实例
- boolean tryLock() // 仅在调用时锁为空闲状态才获取该锁，可以响应中断
- boolean tryLock(long time, TimeUnit unit) // 如果锁在给定的等待时间内空闲，并且当前线程未被中断，则获取锁
- void unlock() // 释放锁

### 9.ReentrantLock 可重入锁
构造方法（不带参数 和带参数 true： 公平锁； false: 非公平锁）

### 10.异步处理框架
Executors 和 Futrure(Java8的CompletableFuture)，Rxjava 等

### 11.JDK 线程池
- Executors
    - newCachedThreadPool  
    创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
        这种类型的线程池特点是：
        - 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。
        - 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。
        - 在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有会造成系统瘫痪。
    - newFixedThreadPool  
    创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。  
    FixedThreadPool是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建线程时所耗的开销的优点。但是，在线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源。
    - newSingleThreadExecutor  
    创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。
    - newScheduleThreadPool  
    创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行。
- ThreadPoolExecutor
Executors 底层方法，参数需要自定义

### 12.ThreadPoolExecutor线程池参数
```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), defaultHandler);
    }
```
- corePoolSize：线程池保有的最小线程数;
- maximumPoolSize：线程池创建的最大线程数;
- keepAliveTime：存活时间;
- unit：keepAliveTime 的时间单位;
- workQueue：任务队列
    - ArrayBlockingQueue 基于数组的有界阻塞队列，按FIFO排序。线程数最大执行拒绝策略;
    - LinkedBlockingQuene 基于链表的无界阻塞队列;
    - SynchronousQuene 一个不缓存任务的阻塞队列。新任务进来时，不会缓存，而是直接被调度执行该任务;
    - PriorityBlockingQueue 具有优先级的无界阻塞队列，优先级通过参数Comparator实现。
- threadFactory：线程工厂对象，可以自定义如何创建线程，如给线程指定name；
- handler：自定义任务的拒绝策略，JDK内置提供了4种拒绝策略
    - AbortPolicy: 直接抛出异常；
    - CallerRunsPolicy：在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务；
    - DiscardPolicy：直接丢弃任务，什么都不做；
    - DiscardOldestPolicy：抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列。

### 13.线程池工作原理
1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。
2. 当调用execute()方法添加一个任务时，线程池会做如下判断：  
a.如果正在运行的线程数小于corePoolSize，那么马上创建线程运行这个任务。  
b.如果正在运行的线程数大于或者等于corePoolSize,那么将这个任务放入队列。  
c.如果这个时候队列满了，而且正在运行的线程数量小于maximumPoolSize,那么还是要创建线程运行这个任务。  
d.如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常，告诉调用者“我不能再接受任务了”

3. 当一个线程完成任务时，它会从队列中取下一个任务来执行。
4. 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于corePoolSize时，那么这个线程会被停用掉，所以线程池的所有任务完成后，它最终会收缩到corePoolSize的大小

### 14.锁
#### Java 实现
- sychronized 关键字
- Lock 接口
#### 悲观锁和乐观锁
悲观锁：假设每一次拿数据，都有认为会被修改，所以给数据库的行或表上锁。要注意for update要用在索引上，不然会锁表。
```sql
START TRANSACTION; # 开启事务
select * from table_name where id=1 for update;
UPDATE table_name SET name= 'nike' WHERE id = 1;
COMMIT; # 提交事务
```
乐观锁：就是很乐观，每次去拿数据的时候都认为别人不会修改。更新时如果version变化了，更新不会成功。
```sql
update status set name='nike',version=(version+1) where id=1 and version=version;
```
#### 自旋锁和适应性自旋锁
自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定
#### 无锁、偏向锁、轻量级锁和重量级锁
轻量级锁自旋实现，CAS的使用
#### 公平锁和非公平锁
- 公平锁：队列排队执行，其他线程全部堵塞，cpu唤醒线程代价大
- 非公平锁：CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁
#### 可重入锁和不可重入锁
status 值，线程占有加1，不可重入判断 satus 值来决定能不能拿到锁
#### 独享锁和共享锁

### 15.对高并发的理解
实在的开发中 还真的没有遇到高并发的场景发生，以下都是纸上谈兵
- web端控制控制输入流，每次点击结束有个等待的过程，避免客户端重复点击，造成没有必要的浪费
- 服务端加服务器，nginx做负载均衡处理，进行分流处理 多台服务器去处理要求
- 存储和获取数据使用redis等缓存，经常被查询的数据使用通过 redis 避免多次查询数据库
- 数据库实行读写分离处理，减轻数据库的负担

#### 从水平扩展和垂直扩展来提高并发能力
水平扩展。使用分布式，增加服务器数量
- 反向代理层使用 DNS 轮询进行水平扩展
- 站点使用 nginx 进行水平扩展
- 服务层使用服务连接池进行水平扩展
- 数据库使用哈希的方式进行水平扩展
垂直扩展
- 增强单机性能
- 提升单机架构性能，如使用缓存、异步和无锁结构减少响应时间

### 16.CAS
Compare and swap 比较交换，CAS利用CPU指令保证操作的原子性。自旋锁，失败不断循环执行直到成功。

### 17.volatile 
禁止指令重排序。表示变量在 CPU 的寄存器中是不确定的，必须从主内存中读取。保证多线程环境下变量的可见性。



